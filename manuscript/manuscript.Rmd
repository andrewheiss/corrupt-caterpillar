---
title: "Full title goes here"
short-title: "Shorter title goes here"
author:
- name: Andrew Heiss
  affiliation: Georgia State University
  email: aheiss@gsu.edu
  url: https://www.andrewheiss.com/
- name: Meng Ye
  affiliation: Georgia State University
  email: mye2@student.gsu.edu
date: "September 10, 2021"
published: Drafting
code-repo: "Access the code at <https://github.com/andrewheiss/corrupt-caterpillar>"
abstract: >-
  Abstract goes here.
keywords: comma, separated, keywords, here
word-count: ""
thanks: >-
  Acknowledgments here if any
reference-section-title: References
bibliography: bibliography.bib
toc: false
title-page: true
endnotes: false
endfloat: false
mainfont: Cochineal
sansfont: Assistant
author-note: >-
  Author note here
correspondence: >-
  Correspondence note here
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
# Figure out output format
is_docx <- knitr::pandoc_to("docx") | knitr::pandoc_to("odt")
is_latex <- knitr::pandoc_to("latex")
is_html <- knitr::pandoc_to("html")

# Word-specific things
table_format <- ifelse(is_docx, "huxtable", "kableExtra")  # Huxtable tables
conditional_dpi <- ifelse(is_docx, 300, 300)  # Higher DPI
conditional_align <- ifelse(is_docx, "default", "center")  # Word doesn't support align

# Knitr options
knitr::opts_chunk$set(
  echo = FALSE, warning = FALSE, message = FALSE,
  tidy.opts = list(width.cutoff = 120),  # Code width
  fig.retina = 3, dpi = conditional_dpi,
  fig.width = 7, fig.asp = 0.618,
  fig.align = conditional_align, out.width = "100%",
  fig.path = "output/figures/",
  cache.path = "output/_cache/",
  fig.process = function(x) {  # Remove "-1" from figure names
    x2 = sub('-\\d+([.][a-z]+)$', '\\1', x)
    if (file.rename(x, x2)) x2 else x
  }
)

# R options
options(
  width = 90,  # Output width
  dplyr.summarise.inform = FALSE,  # Turn off dplyr's summarize() auto messages
  knitr.kable.NA = "",  # Make NAs blank in kables
  kableExtra.latex.load_packages = FALSE,  # Don't add LaTeX preamble stuff
  modelsummary_default = table_format  # Set modelsummary backend
)
```

```{r libraries-data, include=FALSE}
library(tidyverse)
library(patchwork)
library(ggdag)
library(dagitty)
library(targets)
library(kableExtra)
library(here)

withr::with_dir(here::here(), {
  # Load stuff from targets
  source(tar_read(plot_funs))
})

clrs_np <- np_palette()
```

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua [@BaBerrettCoupet:2021]. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.


Ideas:

- Be like @Rohrer:2018 or @BlackwellGlynn:2018 and focus mostly on the DAG framework + a simulated example + an applied example from 1–2 previously published NVSQ or Voluntas papers - make it not super mathy, but still introduce $\operatorname{do}(\cdot)$ notation (like explain how $P(y \mid \operatorname{do}(x))$ is not the same as the observational $P(y \mid x)$, and that's why correlation ≠ causation)
- …or, be like @BaBerrettCoupet:2021 and show a range of methods, like DAGs, RCTs, diff-in-diff, RD, and IV
- …or do both and focus mostly on DAGs but also include a section that maps traditional econometrics methods to the DAG world?

More thoughts:

- Take a similar approach to @BaBerrettCoupet:2021 and search top three nonprofit (also PA?) journals for mentions/uses of specific methods - make a graph of it
- Provide a table of R and Stata commands at the end, like @BaBerrettCoupet:2021?
- Mostly focus on DAGs and confounding, etc. - using DAGs to help with identification - identification is the main challenge of causal inference. You can do it with natural experiments, or you can do it with selection of observables driven by careful causal model and closing backdoors to isolate arrow. 
- Give a @Rohrer:2018 -esque introduction to DAGs + identification, then show an example (simulated data? real data?), then show how econometrics tools can be mapped onto DAGs for identification (and summarize some of the results from diff-in-diff, RDD, and IV papers over the past decade?)



Tentative outline maybe:


```{r dag-associations, fig.width=9, fig.height=2.75, fig.asp=NULL, fig.cap="Three types of relationships in DAGs"}
data_confounder <- dagify(
  Y ~ Z + X,
  X ~ Z,
  coords = list(x = c(X = 1, Y = 3, Z = 2),
                y = c(X = 1, Y = 1, Z = 2))
) %>% 
  tidy_dagitty() %>% 
  mutate(arrow_color = ifelse(name == "Z", clrs_np$orange, "grey80")) %>% 
  mutate(node_color = ifelse(name == "Z", TRUE, FALSE)) 

confounder <- ggplot(data_confounder, aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges(aes(edge_colour = arrow_color), edge_width = 1) +
  geom_dag_point(aes(color = node_color), size = 12) +
  geom_dag_text(data = filter(data_confounder, name != "Z"), size = 4) +
  geom_dag_text(data = filter(data_confounder, name == "Z"), color = "white", size = 4) +
  scale_color_manual(values = c("grey80", clrs_np$orange), guide = "none") +
  coord_cartesian(ylim = c(0.95, 2.05)) +
  labs(title = "Confounder", subtitle = "(Fork)") +
  theme_np_dag() +
  theme(plot.title = element_text(hjust = 0.5, color = clrs_np$orange),
        plot.subtitle = element_text(hjust = 0.5, color = clrs_np$orange))

data_mediator <- dagify(
  Y ~ X + Z,
  Z ~ X,
  coords = list(x = c(X = 1, Y = 3, Z = 2),
                y = c(X = 1, Y = 1, Z = 2))
) %>% 
  tidy_dagitty() %>% 
  mutate(arrow_color = case_when(
    name == "Z" & to == "Y" ~ clrs_np$purple, 
    name == "X" & to == "Z" ~ clrs_np$purple,
    TRUE ~ "grey80")) %>% 
  mutate(node_color = ifelse(name == "Z", TRUE, FALSE)) 

mediator <- ggplot(data_mediator, aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges(aes(edge_colour = arrow_color), edge_width = 1) +
  geom_dag_point(aes(color = node_color), size = 12) +
  geom_dag_text(data = filter(data_mediator, name != "Z"), size = 4) +
  geom_dag_text(data = filter(data_mediator, name == "Z"), color = "white", size = 4) +
  scale_color_manual(values = c("grey80", clrs_np$purple), guide = "none") +
  coord_cartesian(ylim = c(0.95, 2.05)) +
  labs(title = "Mediator", subtitle = "(Chain)") +
  theme_np_dag() +
  theme(plot.title = element_text(hjust = 0.5, color = clrs_np$purple),
        plot.subtitle = element_text(hjust = 0.5, color = clrs_np$purple))

data_collider <- dagify(
  Y ~ X,
  Z ~ X + Y,
  coords = list(x = c(X = 1, Y = 3, Z = 2),
                y = c(X = 1, Y = 1, Z = 2))
) %>% 
  tidy_dagitty() %>% 
  mutate(arrow_color = ifelse(to == "Z", clrs_np$red, "grey80")) %>% 
  mutate(node_color = ifelse(name == "Z", TRUE, FALSE)) 

collider <- ggplot(data_collider, aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges(aes(edge_colour = arrow_color), edge_width = 1) +
  geom_dag_point(aes(color = node_color), size = 12) +
  geom_dag_text(data = filter(data_collider, name != "Z"), size = 4) +
  geom_dag_text(data = filter(data_collider, name == "Z"), color = "white", size = 4) +
  scale_color_manual(values = c("grey80", clrs_np$red), guide = "none") +
  coord_cartesian(ylim = c(0.95, 2.05)) +
  labs(title = "Collider", subtitle = "(Inverted fork)") +
  theme_np_dag() +
  theme(plot.title = element_text(hjust = 0.5, color = clrs_np$red),
        plot.subtitle = element_text(hjust = 0.5, color = clrs_np$red))

combined_associations <- (confounder | plot_spacer() | mediator | plot_spacer() | collider) +
  plot_layout(widths = c(0.32, 0.02, 0.32, 0.02, 0.32))
combined_associations
```



# Causal inference in nonprofit studies

The "causal revolution" / "credibility revolution" has been happening for the past decade in social science disciplines - important because of reasons

How has the discipline of nonprofit studies embraced the causal revolution?

Are there fears of the word "causation" and an emphasis on pure association?

Nonprofit data is very observational - quantitative data from past X years in N journals relies on experimental data Y% of the time, and observational data Z% of the time. 

In this paper, we provide a introductory primer / framework for approaching causal questions with observational data - accessible and approachable guide to nonprofit researchers and practitioners. The framework here is crucial for general academic research, policy analysis, and program evaluation, among other common types of nonprofit research.


# Intro to DAGs

## Paths and causal structures

## Confounding specifically is the main issue with observational data

Especially if it's unmeasured or unobservable…


# Identification with DAGs

## Adjustment and statistical control: blocking backdoor paths

## How to adjust: stratification, including variable in regression model, matching, IPW

## Stop controlling for everything

Bad controls and colliders

Table 2 fallacy + @KeeleStevensonElwert:2020 thing


# Design-based causal inference with DAGs

The language of causal graphs, identification, and adjustment provide a universal grammar for discussing causal effects. Commonly used approaches in econometrics and other social science disciplines can be written as causal graphs (see Figure \@ref(fig:design-based-dags))

```{r design-based-dags, fig.width=9, fig.height=6, fig.asp=NULL, fig.cap="Possible DAGs for common design-based experimental and quasi-experimental approaches to causal inference. Red arrows represent the identified and isolated relationship between treatment $x$ and outcome $y$. Square nodes represent statistical adjustment."}
data_rct <- dagify(
  Y ~ Z + X,
  coords = list(x = c(X = 1, Y = 3, Z = 2),
                y = c(X = 1, Y = 1, Z = 2)),
  labels = c(X = "X = x"),
  exposure = "X",
  outcome = "Y"
) %>% 
  tidy_dagitty() %>% 
  node_status() %>% 
  mutate(arrow_color = ifelse(name == "X", clrs_np$red, "grey80"))

rct <- ggplot(data_rct, aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges(aes(edge_colour = arrow_color), edge_width = 1) +
  geom_dag_point(aes(color = status), size = 12) +
  geom_dag_text(size = 4) +
  geom_dag_text(aes(label = label),
                      nudge_x = 0, nudge_y = 0.2) +
  scale_color_manual(values = c(clrs_np$green, clrs_np$blue), 
                     na.value = clrs_np$yellow, guide = "none") +
  coord_cartesian(ylim = c(0.95, 2.05)) +
  labs(title = "Randomized trial", 
       subtitle = "Randomization deletes all arrows into X") +
  theme_np_dag() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

data_iv <- dagify(Y ~ X + U,
                  X ~ I + U,
                  exposure = "X",
                  outcome = "Y",
                  latent = "U",
                  coords = list(x = c(X = 1, Y = 3, U = 2, I = 0),
                                y = c(X = 1, Y = 1, U = 2, I = 1))) %>% 
  tidy_dagitty() %>% 
  adjust_for(var = "I") %>% 
  node_status() %>% 
  mutate(arrow_color = ifelse(name == "X", clrs_np$red, "grey80"))

iv <- ggplot(data_iv, aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges(aes(edge_colour = arrow_color), edge_width = 1) +
  geom_dag_point(aes(color = status, shape = adjusted), size = 12) +
  geom_dag_text(size = 4) +
  scale_color_manual(values = c(clrs_np$green, "grey80", clrs_np$blue), 
                     na.value = clrs_np$yellow, guide = "none") +
  scale_shape_manual(values = c(15, 19), guide = "none") +
  coord_cartesian(ylim = c(0.95, 2.05)) +
  labs(title = "Instrumental variable", 
       subtitle = "Find effect of instrument (I) on X, then find effect of (X | I) on Y") +
  theme_np_dag() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))


data_diff_diff <- dagify(Y ~ X + Time + Location,
                         X ~ Time + Location,
                         exposure = "X",
                         outcome = "Y",
                         coords = list(x = c(X = 1, Y = 3, Time = 2, Location = 2),
                                       y = c(X = 1, Y = 1, Time = 2, Location = 0))) %>% 
  tidy_dagitty() %>% 
  adjust_for(var = c("Time", "Location")) %>% 
  node_status() %>% 
  mutate(arrow_color = ifelse(name == "X", clrs_np$red, "grey80"))

diff_diff <- ggplot(data_diff_diff, aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges(aes(edge_colour = arrow_color), edge_width = 1) +
  geom_dag_point(aes(color = status, shape = adjusted), size = 12) +
  geom_dag_text(data = filter(data_diff_diff, name %in% c("X", "Y")), size = 4) +
  geom_dag_text(data = filter(data_diff_diff, name == "Location"), 
                nudge_y = 0.37, size = 4) +
  geom_dag_text(data = filter(data_diff_diff, name == "Time"), 
                nudge_y = -0.37, size = 4) +
  scale_color_manual(values = c(clrs_np$green, clrs_np$blue), 
                     na.value = clrs_np$yellow, guide = "none") +
  scale_shape_manual(values = c(15, 19), guide = "none") +
  coord_cartesian(ylim = c(-0.05, 2.05)) +
  labs(title = "Difference-in-differences", 
       subtitle = "Adjust for both time (e.g., year) and location (e.g., country, state)") +
  theme_np_dag() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))


data_rdd <- dagify(Y ~ X + Running + U,
                   X ~ Threshold + U,
                   Running ~ U,
                   Threshold ~ Running,
                   exposure = "X",
                   outcome = "Y",
                   latent = "U",
                   coords = list(x = c(X = 1, Y = 4, Running = 3, Threshold = 2, U = 3),
                                 y = c(X = 1, Y = 1, Running = 2, Threshold = 1.75, U = 3))) %>% 
  tidy_dagitty() %>% 
  adjust_for(var = c("Threshold", "Running")) %>% 
  node_status() %>% 
  mutate(arrow_color = ifelse(name == "X", clrs_np$red, "grey80"),
         name = recode(name, "Running" = "Running\nvariable"),
         linetype = ifelse(name == "U" & to == "X", "21", "solid"))

rdd <- ggplot(data_rdd, aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges(aes(edge_colour = arrow_color, edge_linetype = linetype), edge_width = 1) +
  geom_dag_point(aes(color = status, shape = adjusted), size = 12) +
  geom_dag_text(data = filter(data_rdd, name %in% c("X", "Y", "U")), size = 4) +
  geom_dag_text(data = filter(data_rdd, name == "Running\nvariable"),
                nudge_y = -0.47, size = 4, lineheight = 1) +
  geom_dag_text(data = filter(data_rdd, name == "Threshold"),
                nudge_y = -0.35, size = 4) +
  scale_color_manual(values = c(clrs_np$green, "grey80", clrs_np$blue), 
                     na.value = clrs_np$yellow, guide = "none") +
  scale_shape_manual(values = c(15, 19), guide = "none") +
  coord_cartesian(ylim = c(0.95, 3.05)) +
  labs(title = "Regression discontinuity", 
       subtitle = "Adjust for both the running variable and the threshold") +
  theme_np_dag() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

plot_econometrics <- ((rct | iv) / plot_spacer() / (diff_diff | rdd)) +
  plot_layout(heights = c(0.49, 0.02, 0.49))
plot_econometrics
```


## Experiments

## Instrumental variables

## Diff-in-diff

## Regression discontinuity


# Tools for researchers and practitioners

Code in R and Stata? Point to other resources like The Mixtape, The Effect, Pearl's stuff, Morgan and Winship?


# Conclusion

